x_mean <- c(x_mean,prom)
}
S = matrix(NA, nrow=p, ncol=p)
for (j in 1:p){
for (k in 1:p){
sjk <- 1/(n-1)*sum((X[,j]-x_mean[j])*(X[,k]-x_mean[k]))
S[j,k] <- sjk
}
}
x_mean
S
R <- cov2cor(S)
R
vprop <- eigen(R)
vprop$values
sqrt(vprop$values)
vprop$vectors
simul.pca$x[1:5,]
for (k in 1:p){
carga <- sum((X[,j]-x_mean[j])*(X[,k]-x_mean[k]))
S[j,k] <- sjk
}
loads <- simul.pca$rotation
scale.loads <- 1
library(plotly)
plt <-  plot_ly(M_norm,type = 'scatter3d',x=~Var1,y=~Var2,z=~Var3, mode = 'markers', size = 0.3,
projection =
list(x = list(opacity = 0.1, show = TRUE),
y = list(opacity = 0.1, show = TRUE),
z = list(opacity = 0.1, show = TRUE)),
name = 'Observaciones')
#ns <- rownames(loads)
# add the vectors of the components
for (k in 1:nrow(loads)) {
Lp1 <- c(0, loads[k,1])*scale.loads
Lp2 <- c(0, loads[k,2])*scale.loads
Lp3 <- c(0, loads[k,3])*scale.loads
plt <- plt %>% add_trace(x=Lp1, y=Lp2, z=Lp3,
type="scatter3d", mode="lines",
line = list(width=8),
opacity = 1,
name = paste0('PC',k)
)
}
plt
##  Incluir  la rotación en dos dimensiónes para explicar como se transforma los valores por la cantidad de inercia acumulada desde cada componente
mynames<-c("mpg", "cyl", "disp", "hp", "drat","wt","qsec","vs","am","gear","carb" )
ncols <- length(mynames)
par(mfrow=c(4,3),cex=.9,oma=c(.1,.1,.1,.1))
for(i in 1:ncols){
boxplot(mtcars[,i],horizontal = FALSE,
main = mynames[i])
}
library(corrplot)
corrplot.mixed(cor(mtcars[ , ! names(mtcars) %in% c("vs", "am")]), order = 'AOE')
# Se puede utilizar indistintamente cualquiera de las dos
#mtcars.pca <- prcomp(mtcars[,c(1:7,10,11)], center = TRUE,scale. = TRUE)
#summary(mtcars.pca)
mtcars.pca <- prcomp(mtcars[ , ! names(mtcars) %in% c("vs", "am")] , center = TRUE,scale. = TRUE)
summary(mtcars.pca)
#library(grid)
#library(scales)
#library(plyr)
#library(ggplot2)
#library(ggbiplot)
#ggbiplot(mtcars.pca)
library(factoextra)
fviz_pca_biplot(mtcars.pca)
#ggbiplot(mtcars.pca, labels=rownames(mtcars),choices = 2:3)
fviz_pca_biplot(mtcars.pca, axes = c(2,3))
# calculo de la varianza total
varianza = mtcars.pca$sdev^2 / sum(mtcars.pca$sdev^2)
num.pc <- ncol(mtcars[ , ! names(mtcars) %in% c("vs", "am")])
# Scree plot
qplot(c(1:num.pc), varianza) +
geom_line() +
geom_point(size=4)+
xlab("Componente Principal") +
ylab("Varianza Explicada %") +
ggtitle("Scree Plot (Diagrama de Codo)") +
ylim(0,0.7)
library(mvtnorm)
library(plotly)
library("MASS")
library(psych)
# Simulación de tres variables con matriz de covarianza
set.seed(123456)
my_n1 <- 250                                              # Specify sample size
my_mu1 <- c(0, 0, 0)                                      # Specify the means of the variables
my_Sigma1 <- matrix(c( 1, .62, .81, .62, 1, .3, .81, .3, 1),  # Specify the covariance matrix of the variables
nrow = 3,
ncol = 3,
byrow = TRUE
)
M_norm <- as.data.frame(mvrnorm(n = my_n1, mu = my_mu1, Sigma = my_Sigma1))
colnames(M_norm) <- c('Var1','Var2','Var3')
print(M_norm[1:10,])
library(readr)
library(dplyr)
#lectura del archivo fuente
spg <- read_csv("spg.csv",show_col_types = FALSE)
## Al ser variables con nombres tan largos se renombran
dataspg <- spg %>% rename(T2M = temperature_2_m_above_gnd,
RH = relative_humidity_2_m_above_gnd,
MSL = mean_sea_level_pressure_MSL,
TP = total_precipitation_sfc,
SFA = snowfall_amount_sfc,
TCC = total_cloud_cover_sfc,
HCC = high_cloud_cover_high_cld_lay,
MCC = medium_cloud_cover_mid_cld_lay,
LCC = low_cloud_cover_low_cld_lay,
SWRB = shortwave_radiation_backwards_sfc,
WS10 = wind_speed_10_m_above_gnd,
WD10 = wind_direction_10_m_above_gnd,
WS80 = wind_speed_80_m_above_gnd,
WD80 = wind_direction_80_m_above_gnd,
WS900 = wind_speed_900_mb,
WD900 = wind_direction_900_mb,
WG10 = wind_gust_10_m_above_gnd,
ANG = angle_of_incidence,
ZEN = zenith,
AZM = azimuth,
GP = generated_power_kw)
library(readr)
library(dplyr)
#lectura del archivo fuente
spg <- read_csv("spg.csv",show_col_types = FALSE)
## Al ser variables con nombres tan largos se renombran
dataspg <- spg %>% rename(T2M = temperature_2_m_above_gnd,
RH = relative_humidity_2_m_above_gnd,
MSL = mean_sea_level_pressure_MSL,
TP = total_precipitation_sfc,
SFA = snowfall_amount_sfc,
TCC = total_cloud_cover_sfc,
HCC = high_cloud_cover_high_cld_lay,
MCC = medium_cloud_cover_mid_cld_lay,
LCC = low_cloud_cover_low_cld_lay,
SWRB = shortwave_radiation_backwards_sfc,
WS10 = wind_speed_10_m_above_gnd,
WD10 = wind_direction_10_m_above_gnd,
WS80 = wind_speed_80_m_above_gnd,
WD80 = wind_direction_80_m_above_gnd,
WS900 = wind_speed_900_mb,
WD900 = wind_direction_900_mb,
WG10 = wind_gust_10_m_above_gnd,
ANG = angle_of_incidence,
ZEN = zenith,
AZM = azimuth,
GP = generated_power_kw)
# Escriba su respuesta acá
library(readr)
library(dplyr)
#lectura del archivo fuente
spg <- read_csv("spg.csv",show_col_types = FALSE)
## Al ser variables con nombres tan largos se renombran
dataspg <- spg %>% rename(T2M = temperature_2_m_above_gnd,
RH = relative_humidity_2_m_above_gnd,
MSL = mean_sea_level_pressure_MSL,
TP = total_precipitation_sfc,
SFA = snowfall_amount_sfc,
TCC = total_cloud_cover_sfc,
HCC = high_cloud_cover_high_cld_lay,
MCC = medium_cloud_cover_mid_cld_lay,
LCC = low_cloud_cover_low_cld_lay,
SWRB = shortwave_radiation_backwards_sfc,
WS10 = wind_speed_10_m_above_gnd,
WD10 = wind_direction_10_m_above_gnd,
WS80 = wind_speed_80_m_above_gnd,
WD80 = wind_direction_80_m_above_gnd,
WS900 = wind_speed_900_mb,
WD900 = wind_direction_900_mb,
WG10 = wind_gust_10_m_above_gnd,
ANG = angle_of_incidence,
ZEN = zenith,
AZM = azimuth,
GP = generated_power_kw)
# Escriba su respuesta acá
#cor(spg)
library(corrplot)
corrplot.mixed(cor(spg))
# Escriba su respuesta acá
spg.pca <- prcomp(spg, center = TRUE,scale. = TRUE)
summary(spg.pca)
#  Escriba su respuesta acá
# calculo de la varianza total
varianza = spg.pca$sdev^2 / sum(spg.pca$sdev^2)
num.pc <- ncol(spg)
# Scree plot
qplot(c(1:num.pc), varianza) +
geom_line() +
geom_point(size=4)+
xlab("Componente Principal") +
ylab("Varianza Explicada %") +
ggtitle("Scree Plot (Diagrama de Codo)") +
ylim(0,0.3)
spg.pca$sdev
library(factoextra)
fviz_screeplot(spg.pca, ncp = 15)
#  Escriba su respuesta acá
library(factoextra)
spg.pca <- prcomp(dataspg, center = TRUE,scale. = TRUE)
fviz_pca_biplot(spg.pca,alpha.ind =.1, label = c("var"))
# Escriba su respuesta acá
fviz_pca_biplot(spg.pca,alpha.ind =.1, label = c("var"),axes = c(2,3),)
spg <- read_csv("spg.csv")
data <- spg %>% rename(T2M = temperature_2_m_above_gnd,
RH = relative_humidity_2_m_above_gnd,
MSL = mean_sea_level_pressure_MSL,
TP = total_precipitation_sfc,
SFA = snowfall_amount_sfc,
TCC = total_cloud_cover_sfc,
HCC = high_cloud_cover_high_cld_lay,
MCC = medium_cloud_cover_mid_cld_lay,
LCC = low_cloud_cover_low_cld_lay,
SWRB = shortwave_radiation_backwards_sfc,
WS10 = wind_speed_10_m_above_gnd,
WD10 = wind_direction_10_m_above_gnd,
WS80 = wind_speed_80_m_above_gnd,
WD80 = wind_direction_80_m_above_gnd,
WS900 = wind_speed_900_mb,
WD900 = wind_direction_900_mb,
WG10 = wind_gust_10_m_above_gnd,
ANG = angle_of_incidence,
ZEN = zenith,
AZM = azimuth,
GP = generated_power_kw)
spg <- read_csv("spg.csv")
data <- spg %>% rename(T2M = temperature_2_m_above_gnd,
RH = relative_humidity_2_m_above_gnd,
MSL = mean_sea_level_pressure_MSL,
TP = total_precipitation_sfc,
SFA = snowfall_amount_sfc,
TCC = total_cloud_cover_sfc,
HCC = high_cloud_cover_high_cld_lay,
MCC = medium_cloud_cover_mid_cld_lay,
LCC = low_cloud_cover_low_cld_lay,
SWRB = shortwave_radiation_backwards_sfc,
WS10 = wind_speed_10_m_above_gnd,
WD10 = wind_direction_10_m_above_gnd,
WS80 = wind_speed_80_m_above_gnd,
WD80 = wind_direction_80_m_above_gnd,
WS900 = wind_speed_900_mb,
WD900 = wind_direction_900_mb,
WG10 = wind_gust_10_m_above_gnd,
ANG = angle_of_incidence,
ZEN = zenith,
AZM = azimuth,
GP = generated_power_kw)
library(psych)
library(corrplot)
library(dplyr)
library(ggplot2)
library(car)
library(readr)
spg <- read_csv("spg.csv")
data <- spg %>% rename(T2M = temperature_2_m_above_gnd,
RH = relative_humidity_2_m_above_gnd,
MSL = mean_sea_level_pressure_MSL,
TP = total_precipitation_sfc,
SFA = snowfall_amount_sfc,
TCC = total_cloud_cover_sfc,
HCC = high_cloud_cover_high_cld_lay,
MCC = medium_cloud_cover_mid_cld_lay,
LCC = low_cloud_cover_low_cld_lay,
SWRB = shortwave_radiation_backwards_sfc,
WS10 = wind_speed_10_m_above_gnd,
WD10 = wind_direction_10_m_above_gnd,
WS80 = wind_speed_80_m_above_gnd,
WD80 = wind_direction_80_m_above_gnd,
WS900 = wind_speed_900_mb,
WD900 = wind_direction_900_mb,
WG10 = wind_gust_10_m_above_gnd,
ANG = angle_of_incidence,
ZEN = zenith,
AZM = azimuth,
GP = generated_power_kw)
describe(data)
corrmat <- cor(data)
corrplot(corrmat,method="ellipse")
X <- data
R=cor(X)
KMO(r=R)
cortest.bartlett(R,n = nrow(X))
fafitfree <- fa(data,nfactors = ncol(X), rotate = "none")
n_factors <- length(fafitfree$e.values)
scree     <- data.frame(
Factor_n =  as.factor(1:n_factors),
Eigenvalue = fafitfree$e.values)
ggplot(scree, aes(x = Factor_n, y = Eigenvalue, group = 1)) +
geom_point() + geom_line() +
xlab("Number of factors") +
ylab("Initial eigenvalue") +
labs( title = "Scree Plot",
subtitle = "(Based on the unreduced correlation matrix)")
parallel <- fa.parallel(X)
#fm:  minres pa gls ols ml
fa.none <- fa(r=data,
nfactors = 3,  # covar = FALSE, SMC = TRUE,
fm="pa", # type of factor analysis we want to use (“pa” is principal axis factoring)
max.iter=100, # (50 is the default, but we have changed it to 100
rotate="varimax") # none rotation
print(fa.none)
print(fa(data,3,fm='pa',max.iter=100,rotate='varimax')$loadings,cut=.2)
fa.diagram(fa.none)
# Realizar el análisis PCA
datos_pca <- prcomp(datos, scale. = TRUE)
library(readr)
library(dplyr)
library(caret)
datos <- read.csv('Spotify_Youtube.csv')
colnames(datos)
str(datos)
# Eliminación de variables categóricas:
datos <- datos %>% select(-one_of('X', 'Artist', 'Track', 'Album', 'Album_type', 'Title', 'official_video', 'Url_spotify', 'Uri', 'Url_youtube', 'Channel', 'Description', 'Licensed'))
colnames(datos)
# Calcula la cantidad de datos faltantes por columna
datos_faltantes <- colSums(is.na(datos))
# Imprime la cantidad de datos faltantes por columna
print(datos_faltantes)
# Eliminar filas con datos faltantes
datos <- na.omit(datos)
# calcula y asigna la relación "views_likes_ratio" entre las variables "Views" y "Likes"
datos$views_likes_ratio <-   datos$Likes / datos$Views
process <- preProcess(as.data.frame(datos), method=c("range"))
datos_df <-  predict(process, as.data.frame(datos))#log(datos)  # Crear una copia del conjunto de datos original
summary(datos_df)
# Imprime el encabezado del conjunto de datos resultante
library(knitr)
library(kableExtra)
tabla <- head(datos_df)[1:8]
Tabla <- kable(tabla, col.names = colnames(tabla)) %>%
kable_styling(font_size = 10) %>%
add_header_above(header = NULL)
Tabla
library(knitr)
library(kableExtra)
resumen_estadistico <- summary(datos_df)
Tabla_estadisticas <- kable(resumen_estadistico) %>%
kable_styling(font_size = 10)
Tabla_estadisticas
# Histogramas de todas las variables
# Ajusta los márgenes de la figura
par(mar = c(2, 2, 2, 2))
# Crea una matriz de subplots para los histogramas
par(mfrow = c(4, 2))
# Itera sobre las primeras ocho variables y crea el histograma
variables <- colnames(datos_df)[1:16]
for (i in 1:length(variables)) {
boxplot(datos_df[, variables[i]], main = variables[i], xlab = "", col = "lightblue")
}
# Restaura el diseño de gráficos a una sola columna y una fila
par(mfrow = c(1, 1))
library(reshape2)
library(ggplot2)
# Calculo de la matriz de correlación
correlaciones <- cor(datos_df)
# Convertir la matriz en un dataframe
cor_df <- melt(correlaciones)
# Graficar la matriz de correlación con un heatmap y anotaciones en las celdas
ggplot(cor_df, aes(x=Var1, y=Var2, fill=value)) +
geom_tile() +
scale_fill_gradient2(low="blue", mid="white", high="red",
midpoint=0, limit=c(-1,1), space="Lab", name="Correlación") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 90, vjust = 1,
size = 10, hjust = 1),
axis.text.y = element_text(size = 10)) +
coord_fixed() +
geom_text(aes(label = round(value, 2)), size = 2, color = "black", alpha = 0.7) +
theme(plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm"))
library(reshape2)
library(ggplot2)
# Calculo de la matriz de correlación
datos_v_l_r <- datos_df %>% select(one_of('Stream', 'Comments', 'Likes', 'Views', 'Danceability', 'Loudness'))
correlaciones_vlr <- cor(datos_v_l_r)
# Convertir la matriz en un dataframe
cor_df_vlr <- melt(correlaciones_vlr)
# Graficar la matriz de correlación con un heatmap y anotaciones en las celdas
ggplot(cor_df_vlr, aes(x=Var1, y=Var2, fill=value)) +
geom_tile() +
scale_fill_gradient2(low="blue", mid="white", high="red",
midpoint=0, limit=c(-1,1), space="Lab", name="Correlación") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 90, vjust = 1,
size = 10, hjust = 1),
axis.text.y = element_text(size = 10)) +
coord_fixed() +
geom_text(aes(label = round(value, 2)), size = 2, color = "black", alpha = 0.7) +
theme(plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm"))
pairs.panels(datos_v_l_r,
smooth = TRUE,      # If TRUE, draws loess smooths
scale = FALSE,      # If TRUE, scales the correlation text font
density = TRUE,     # If TRUE, adds density plots and histograms
ellipses = TRUE,    # If TRUE, draws ellipses
method = "pearson", # Correlation method (also "spearman" or "kendall")
pch = 21,           # pch symbol
lm = FALSE,         # If TRUE, plots linear fit rather than the LOESS (smoothed) fit
cor = TRUE,         # If TRUE, reports correlations
jiggle = FALSE,     # If TRUE, data points are jittered
factor = 2,         # Jittering factor
hist.col = 4,       # Histograms color
stars = TRUE,       # If TRUE, adds significance level with stars
ci = TRUE)          # If TRUE, adds confidence intervals
# Ajuste de regresión lineal múltiple para predecir la variable views_likes_ratio.
datos_RL <- lm(Likes~Danceability
#+ Energy
#+ Key
+ Loudness
#+ Speechiness
#+ Acousticness
#+ Instrumentalness
#+ Liveness
#+ Valence
#+ Tempo
#+ Duration_ms,
+ Views
#+ Likes
+ Comments
+ Stream,
data = datos_v_l_r)
datos_RL
library(knitr)
library(kableExtra)
# Obtener el resumen del modelo
resumen_modelo <- summary(datos_RL)
# Crear una tabla con los coeficientes y los estadísticos de interés
tabla_resumen <- data.frame(
Coefficients = rownames(resumen_modelo$coefficients),
Estimate = resumen_modelo$coefficients[, "Estimate"],
`Std. Error` = resumen_modelo$coefficients[, "Std. Error"],
`t value` = resumen_modelo$coefficients[, "t value"],
`Pr(>|t|)` = resumen_modelo$coefficients[, "Pr(>|t|)"],
`Multiple R-squared` = resumen_modelo$r.squared,
`Adjusted R-squared` = resumen_modelo$adj.r.squared
)
# Formatear la tabla con kable y kableExtra
tabla_formateada <- kable(tabla_resumen, align = "c", caption = "Resumen del modelo de regresión lineal múltiple datos_RL") %>%
kable_styling(bootstrap_options = "striped", full_width = FALSE, font_size = 12)
# Imprimir la tabla
tabla_formateada
# Ajuste de regresión lineal múltiple para predecir la variable alcoholviews_likes_ratio.
datos_RL1 <- lm(Likes~Danceability
#+ Energy
#+ Key
#+ Loudness
#+ Speechiness
#+ Acousticness
#+ Instrumentalness
#+ Liveness
#+ Valence
#+ Tempo
#+ Duration_ms,
+ Views
#+ Likes
+ Comments
+ Stream,
data = datos_df)
datos_RL1
library(knitr)
library(kableExtra)
# Resumen del modelo
resumen_modelo <- summary(datos_RL1)
# Crear una tabla con los coeficientes y los estadísticos
tabla_resumen <- data.frame(
Coefficients = rownames(resumen_modelo$coefficients),
Estimate = resumen_modelo$coefficients[, "Estimate"],
`Std. Error` = resumen_modelo$coefficients[, "Std. Error"],
`t value` = resumen_modelo$coefficients[, "t value"],
`Pr(>|t|)` = resumen_modelo$coefficients[, "Pr(>|t|)"],
`Multiple R-squared` = resumen_modelo$r.squared,
`Adjusted R-squared` = resumen_modelo$adj.r.squared
)
# Formatear la tabla con kable y kableExtra
tabla_formateada <- kable(tabla_resumen, align = "c", caption = "Resumen del modelo de regresión lineal múltiple datos_RL1") %>%
kable_styling(bootstrap_options = "striped", full_width = FALSE, font_size = 12)
# Imprimir la tabla
tabla_formateada
# Realizar el análisis PCA
datos_pca <- prcomp(datos, scale. = TRUE)
# Calcular el porcentaje de varianza explicada por cada componente principal
var_exp <- (datos_pca$sdev^2) / sum(datos_pca$sdev^2) * 100
# Agregar los porcentajes de varianza a la matriz
loadings1 <- cbind(datos_pca$rotation, var_exp)
# Ordenar las filas de la matriz
#loadings <- loadings[order(abs(loadings[,1]), decreasing = TRUE),]
# Imprimir los resultados
print(loadings1, digits=2)
tabla_formateada_pca <- kable(loadings1, align = "c", caption = "Relación de participación de las variables en los componentes") %>%
kable_styling(bootstrap_options = "striped", full_width = FALSE, font_size = 12)
# Imprimir la tabla
tabla_formateada_pca
library(factoextra)
fviz_pca_biplot(datos_pca, alpha.ind = 0.1,label = c("var"))
# calculo de la varianza total
varianza = datos_pca$sdev^2 / sum(datos_pca$sdev^2)
num.pc <- ncol(datos)
# Scree plot
qplot(c(1:num.pc), varianza) +
geom_line() +
geom_point(size=4)+
xlab("Componente Principal") +
ylab("Varianza Explicada %") +
ggtitle("Scree Plot (Diagrama de Codo)") +
ylim(0,0.25)
fviz_eig(datos_pca)
datos_cluster <- scale(datos %>% select(-one_of('views_likes_ratio')), scale=TRUE)
# Calculate the Distance
dist_datos <- dist(datos_cluster, method = "euclidean")
# Perform the hierarchical clustering using the complete linkage
hc_datos_complete <- hclust(dist_datos,method="complete")
# Perform the hierarchical clustering using the single linkage
hc_datos_single <- hclust(dist_datos,method="single")
